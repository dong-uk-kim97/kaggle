{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-o-Gf7Ef51Pu"
      },
      "outputs": [],
      "source": [
        "MAX_ROUNDS = 400\n",
        "OPTIMIZE_ROUNDS = False\n",
        "LEARNING_RATE = 0.07\n",
        "EARLY_STOPPING_ROUNDS = 10\n",
        "# EARLY_STOPPING_ROUNDS를 매우 높게 설정했습니다(50, OPTIMIZE_ROUNDS가 설정되어 있을 때)\n",
        "# 실제로 early stopping을 사용하고 싶다면 EALY_STOPPING_ROUNDS를 줄여주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- rounds의 적절한 수에 대한 아이디어를 얻기 위해 초기에 MAX_ROUNDS를 매우 높게 설정하고 OPTIMIZE_ROUNDS를 사용하는 것을 추천합니다.\n",
        "- 모든 fold 중에서 best_ntree_limit의 최댓값에 가까워야하며 모델이 적절하게 정규화되었다면 조금 더 높을 수 있습니다. \n",
        "- 아니면 verbose=True로 설정하여 디테일을 살펴본 후 모든 fold에 잘 작동되는 round를 찾습니다.\n",
        "- 그 후, OPTIMIZE_ROUNDS를 끄고, 최적의 MAX_ROUNDS의 값을 설정합니다."
      ],
      "metadata": {
        "id": "NIdb6Wdm6r9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 fold에서 가장 적합한 round를 설정해 early stopping하는 가장 큰 문제점은 validation data에 overfitting된다는 것입니다. \n",
        "- 그러므로 test data를 예측하는데 최적의 모델을 만들지 못할 가능성이 있고, 만약 다른 모델과의 stacking/ensembling을 위한 validation data를 생성하는데 사용된다면 이 모델이 앙상블에 너무 많은 weight을 갖게 됩니다.\n",
        "- 또 다른 가능성(XGBoost의 default)은 최적의 round보다 early stopping이 일어났을 때의 round를 사용한다는 것입니다."
      ],
      "metadata": {
        "id": "4QR8vBW98Jv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "early stopping이 overfitting 문제는 해결하지만, 20-round early stopping에서 일정한 갓의 round보다 validation score가 낮게 나온 것을 봤을때, early stopping은 약간 underfitting된 것처럼 보입니다."
      ],
      "metadata": {
        "id": "ISDTSwxT8wdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import jit\n",
        "import time\n",
        "import gc"
      ],
      "metadata": {
        "id": "iZYCyBI_9NrZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gini 계산\n",
        "\n",
        "@jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
        "def eval_gini(y_true, y_prob):\n",
        "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
        "  y_true = y_true[np.argsort(y_prob)]\n",
        "  ntrue = 0\n",
        "  gini = 0\n",
        "  delta = 0\n",
        "  n= len(y_true)\n",
        "  for i in range(n-1, -1,-1):\n",
        "    y_i = y_true[i]\n",
        "    ntrue +=y_i\n",
        "    gini += y_i * delta\n",
        "    delta += 1 - y_i\n",
        "  gini = 1 - 2*gini /(ntrue * (n-ntrue))\n",
        "  return gini"
      ],
      "metadata": {
        "id": "84sfNJ6q93Zu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_xgb(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  gini_score = -eval_gini(labels, preds)\n",
        "  # 해당 커널에서 분류에 사용한 XGBClassifier모델은 평가 지표로 rsme와 같은 값을 사용 -> 즉 오류의 최솟값을 찾음\n",
        "  # 이 대회의 평가 지표인 지니 계수 : 0.5에 가까울수록(값이 클수록) 좋은 값이기 때문에 -를 붙여주는 함수를 생성\n",
        "  return [('gini', gini_score)]"
      ],
      "metadata": {
        "id": "zdFbR6xz-iw7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**범주형 변수 인코딩**\n",
        "\n",
        "해당 커널에서는 distinct value가 많은 ps_car_11_cat 변수들에 대해서는 mean encoding을 사용하였고, 나머지 범주형 변수들에 대해서는 더미 변수를 생성하는 one-hot encoding의 방식 사용합니다.\n"
      ],
      "metadata": {
        "id": "8aM47R_p_Eyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean encoding이란?\n",
        "\n",
        "<목표>\n",
        "\n",
        "카테고리 변수에 대해 (여기서는 104개의 카테고리를 가진 ps_car_11_cat 변수에 대해) 단순하게 0, 1로 구분된 target값에 대한 의미를 가지도록 만드는 것\n",
        "\n",
        "카테고리 변수의 Label 값에 따라서 Target값의 평균을 구해 각 Label이 Target과 가지는 상관성, 영향 도출\n",
        "\n",
        "<문제점>\n",
        "1. target값을 이용해 계산하기 때문에 overfitting의 문제가 발생할 수 있음 -> 이 커널에서는 noise를 추가하는 방식으로 이 문제를 해결\n",
        "2. test데이터와 train데이터 간의 분포가 다른 경우(ex. 한쪽이 불균형 데이터인 경우) 이때도 마찬가지로 overfitting의 문제 발생 가능 → Smoothing을 통해 문제 해결\n",
        "\n",
        "$$label_c = \\frac{p_c*n_c+p_{global}*α}{n_c+α}$$"
      ],
      "metadata": {
        "id": "4W0xJppv_Vsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(series, noise_level):\n",
        "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "\n",
        "def target_encode(trn_series=None, \n",
        "                  val_series=None,\n",
        "                  tst_series=None,\n",
        "                  target=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "    '''\n",
        "    trn_series : training categorical feature as a pd.Series\n",
        "    tst_series : test categorical feature as a pd.Series\n",
        "    target : target data as a pd.Series\n",
        "    min_samples_leaf (int): category 평균을 고려하기 위한 최소 샘플 수\n",
        "    smoothing (int): categorical average와 prior의 균형을 맞추기 위한 smoothing effect\n",
        "    '''\n",
        "    assert len(trn_series) == len(target)\n",
        "    assert trn_series.name == tst_series.name\n",
        "    temp = pd.concat([trn_series, target], axis=1)\n",
        "    # Compute target mean\n",
        "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
        "    \n",
        "    # Compute smoothing\n",
        "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "    \n",
        "    # Apply average function to all target data\n",
        "    prior = target.mean()\n",
        "    \n",
        "    # The bigger the count the less full_avg is taken into account\n",
        "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "    \n",
        "    # Apply averages to trn and tst series\n",
        "    ft_trn_series = pd.merge(\n",
        "        trn_series.to_frame(trn_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=trn_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    \n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_trn_series.index = trn_series.index\n",
        "    ft_val_series = pd.merge(\n",
        "        val_series.to_frame(val_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=val_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    \n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_val_series.index = val_series.index\n",
        "    ft_tst_series = pd.merge(\n",
        "        tst_series.to_frame(tst_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=tst_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    \n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_tst_series.index = tst_series.index\n",
        "    \n",
        "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "metadata": {
        "id": "4sLJJDYOREXU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Porto Seguro’s Safe Driver Prediction/train.csv', na_values='-1')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Porto Seguro’s Safe Driver Prediction/test.csv', na_values='-1')"
      ],
      "metadata": {
        "id": "wnAl-vRPEcqr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = [\n",
        "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
        "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
        "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
        "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
        "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
        "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
        "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
        "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
        "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
        "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
        "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
        "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
        "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
        "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
        "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
        "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
        "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
        "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
        "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
        "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
        "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
        "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
        "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
        "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
        "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
        "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
        "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
        "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
        "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
        "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
        "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
        "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
        "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
        "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
        "]\n",
        "\n",
        "# add combinations\n",
        "combs = [\n",
        "    ('ps_reg_01', 'ps_car_02_cat'),\n",
        "    ('ps_reg_01', 'ps_car_04_cat'),\n",
        "]"
      ],
      "metadata": {
        "id": "DF-3g-4sFLkD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process data\n",
        "id_test = test_df['id'].values\n",
        "id_train = train_df['id'].values\n",
        "y = train_df['target']\n",
        "\n",
        "start = time.time()\n",
        "for n_c, (f1, f2) in enumerate(combs):\n",
        "  name1 = f1 + '_plus_' + f2\n",
        "  print('current feature %60s %4d in %5.1f'% (name1, n_c +1, (time.time()-start)/60))\n",
        "  train_df[name1] = train_df[f1].apply(lambda x: str(x)) + '_' + train_df[f2].apply(lambda x:str(x))\n",
        "  test_df[name1] = test_df[f1].apply(lambda x: str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
        "\n",
        "  # Label Encode\n",
        "  lbl = LabelEncoder()\n",
        "  lbl.fit(list(train_df[name1].values)+list(test_df[name1].values))\n",
        "  train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
        "  test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
        "\n",
        "  train_features.append(name1)\n",
        "\n",
        "X = train_df[train_features]\n",
        "test_df = test_df[train_features]\n",
        "\n",
        "f_cats = [f for f in X.columns if '_cat' in f]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEb_Ryl_F5kg",
        "outputId": "68b1023b-c164-4a6f-dbbe-419fc7ac8adf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0\n",
            "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0"
      ],
      "metadata": {
        "id": "1NT-h5lcH451"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up folds\n",
        "K =5\n",
        "kf = StratifiedKFold(n_splits=K, random_state=1, shuffle=True)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "jLP7uwu4H8WN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up classifier\n",
        "model = XGBClassifier(\n",
        "    n_estimators = MAX_ROUNDS,\n",
        "    max_depth=4,\n",
        "    objective='binary:logistic',\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    subsample=.8,\n",
        "    min_child_weight=6,\n",
        "    colsample_bytree=.8,\n",
        "    scale_pos_weight=1.6,\n",
        "    gamma=10,\n",
        "    reg_alpha=8,\n",
        "    reg_lambda=1.3,\n",
        "    )"
      ],
      "metadata": {
        "id": "vucPqtZpIMRa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run CV\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_df, train_df[\"target\"])):\n",
        "    \n",
        "    # Create data for this fold\n",
        "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
        "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
        "    X_test = test_df.copy()\n",
        "    print( \"\\nFold \", i)\n",
        "    \n",
        "    # Enocode data\n",
        "    for f in f_cats:\n",
        "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
        "                                                        trn_series=X_train[f],\n",
        "                                                        val_series=X_valid[f],\n",
        "                                                        tst_series=X_test[f],\n",
        "                                                        target=y_train,\n",
        "                                                        min_samples_leaf=200,\n",
        "                                                        smoothing=10,\n",
        "                                                        noise_level=0\n",
        "                                                        )\n",
        "    # Run model for this fold\n",
        "    if OPTIMIZE_ROUNDS:\n",
        "        eval_set=[(X_valid,y_valid)]\n",
        "        fit_model = model.fit( X_train, y_train, \n",
        "                               eval_set=eval_set,\n",
        "                               eval_metric=gini_xgb,\n",
        "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "                               verbose=False\n",
        "                             )\n",
        "        print( \"  Best N trees = \", model.best_ntree_limit )\n",
        "        print( \"  Best gini = \", model.best_score )\n",
        "    else:\n",
        "        fit_model = model.fit( X_train, y_train )\n",
        "        \n",
        "    # Generate validation predictions for this fold\n",
        "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
        "    # predict_proba의 출력은 각 클래스에 대한 확률, 이진 분류에서는 항상 사이즈가 (n_samples, 2)\n",
        "    print(\"  Gini = \", eval_gini(y_valid, pred))\n",
        "    y_valid_pred.iloc[test_index] = pred\n",
        "    \n",
        "    # Accumulate test set predictions\n",
        "    y_test_pred += fit_model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    del X_test, X_train, X_valid, y_train\n",
        "    \n",
        "y_test_pred /= K\n",
        "\n",
        "print( \"\\nGini for full training set:\" )\n",
        "eval_gini(y, y_valid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53wDwS0HI25-",
        "outputId": "f118cfd6-38da-40a8-8bee-c9d1231b04f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a2c16212127a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-3-a2c16212127a> (5)\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  @jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
            "<ipython-input-3-a2c16212127a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 11:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    <source elided>\n",
            "  n= len(y_true)\n",
            "  for i in range(n-1, -1,-1):\n",
            "  ^\n",
            "\n",
            "  @jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Gini =  0.277970113826814\n",
            "\n",
            "Fold  1\n",
            "  Gini =  0.2822639719405956\n",
            "\n",
            "Fold  2\n",
            "  Gini =  0.2870486624992178\n",
            "\n",
            "Fold  3\n",
            "  Gini =  0.2857870475260117\n",
            "\n",
            "Fold  4\n",
            "  Gini =  0.2922329139920077\n",
            "\n",
            "Gini for full training set:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-a2c16212127a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-3-a2c16212127a> (5)\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  @jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
            "<ipython-input-3-a2c16212127a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 11:\n",
            "def eval_gini(y_true, y_prob):\n",
            "    <source elided>\n",
            "  n= len(y_true)\n",
            "  for i in range(n-1, -1,-1):\n",
            "  ^\n",
            "\n",
            "  @jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-3-a2c16212127a>\", line 5:\n",
            "def eval_gini(y_true, y_prob):\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2850342650879212"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save validation predictions for stacking/ensembling\n",
        "val = pd.DataFrame()\n",
        "val['id'] = id_train\n",
        "val['target'] = y_valid_pred.values\n",
        "val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"
      ],
      "metadata": {
        "id": "CrDTLfuZN8l5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create submission file\n",
        "sub = pd.DataFrame()\n",
        "sub['id'] = id_test\n",
        "sub['target'] = y_test_pred\n",
        "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"
      ],
      "metadata": {
        "id": "oIoezNaUN3JP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 참고\n",
        "\n",
        "https://www.kaggle.com/code/aharless/xgboost-cv-lb-284/notebook \n",
        "\n",
        "https://kubig-2021-2.tistory.com/38"
      ],
      "metadata": {
        "id": "HJV8Hvb_6QXZ"
      }
    }
  ]
}